# wiki-to-azure-lake-pipeline
A production-ready data engineering workflow built with Apache Airflow. The pipeline automatically crawls football statistics from Wikipedia, performs data cleaning and transformations, and loads the processed data into Azure Data Lake for scalable storage and downstream analytics. Containerized with Docker for reproducible deployment.
